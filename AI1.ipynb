{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONWBqi8U2Cp+Nthb/Tj/GT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anchaljethliya/Javascript_learning/blob/main/AI1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZiXMoYLwe_z",
        "outputId": "d7514ce2-d6d8-4eaf-ab00-6b5afbd45070"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Perceptron for AND gate...\n",
            "Results for AND gate:\n",
            "Input: [0 0], Predicted: 0\n",
            "Input: [0 1], Predicted: 0\n",
            "Input: [1 0], Predicted: 0\n",
            "Input: [1 1], Predicted: 1\n",
            "-\n",
            "Training Perceptron for NOT gate...\n",
            "Results for NOT gate:\n",
            "Input: [0], Predicted: 1\n",
            "Input: [1], Predicted: 0\n",
            "-\n",
            "Training Perceptron for NAND gate...\n",
            "Results for NAND gate:\n",
            "Input: [0 0], Predicted: 1\n",
            "Input: [0 1], Predicted: 1\n",
            "Input: [1 0], Predicted: 1\n",
            "Input: [1 1], Predicted: 0\n",
            "-\n",
            "Training Perceptron for XOR gate...\n",
            "Results for XOR gate:\n",
            "Input: [0 0], Predicted: 0\n",
            "Input: [0 1], Predicted: 1\n",
            "Input: [1 0], Predicted: 0\n",
            "Input: [1 1], Predicted: 1\n",
            "-\n",
            "Training Perceptron for XNOR gate...\n",
            "Results for XNOR gate:\n",
            "Input: [0 0], Predicted: 0\n",
            "Input: [0 1], Predicted: 1\n",
            "Input: [1 0], Predicted: 1\n",
            "Input: [1 1], Predicted: 1\n",
            "-\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, input_size, lr=0.1, epochs=10):\n",
        "        self.weights = np.random.rand(input_size + 1)  # Extra weight for bias\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "\n",
        "    def activation(self, x):\n",
        "        return 1 if x >= 0 else 0\n",
        "\n",
        "    def predict(self, x):\n",
        "        x = np.insert(x, 0, 1)  # Adding bias term\n",
        "        return self.activation(np.dot(self.weights, x))\n",
        "\n",
        "    def train(self, X, y):\n",
        "        for _ in range(self.epochs):\n",
        "            for xi, target in zip(X, y):\n",
        "                xi = np.insert(xi, 0, 1)  # Adding bias term\n",
        "                output = self.activation(np.dot(self.weights, xi))\n",
        "                self.weights += self.lr * (target - output) * xi\n",
        "\n",
        "# Training data for logic gates\n",
        "logic_gates = {\n",
        "    \"AND\": (np.array([[0,0], [0,1], [1,0], [1,1]]), np.array([0, 0, 0, 1])),\n",
        "    \"NOT\": (np.array([[0], [1]]), np.array([1, 0])),\n",
        "    \"NAND\": (np.array([[0,0], [0,1], [1,0], [1,1]]), np.array([1, 1, 1, 0])),\n",
        "    \"XOR\": (np.array([[0,0], [0,1], [1,0], [1,1]]), np.array([0, 1, 1, 0])),\n",
        "    \"XNOR\": (np.array([[0,0], [0,1], [1,0], [1,1]]), np.array([1, 0, 0, 1]))\n",
        "}\n",
        "\n",
        "# Train perceptron and test it on logic gates\n",
        "for gate, (X, y) in logic_gates.items():\n",
        "    print(f\"Training Perceptron for {gate} gate...\")\n",
        "    perceptron = Perceptron(input_size=X.shape[1])\n",
        "    perceptron.train(X, y)\n",
        "\n",
        "    print(f\"Results for {gate} gate:\")\n",
        "    for xi in X:\n",
        "        print(f\"Input: {xi}, Predicted: {perceptron.predict(xi)}\")\n",
        "    print(\"-\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BO7tI1Zkwf--"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}